{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "\n",
    "Machine Learning is the field of study that gives computers the capability to learn without being explicitly programmed. \"Machine Learning\" emphasizes that the computer program (or machine) must do some work after it is given data.  The Learning step is made explicit. Eventhough Machine Learning was started in use to recognize patterns, Researchers started applying Machine Learning to Robotics (reinforcement learning, manipulation, motion planning, grasping), to genome data, as well as to predict financial markets. \n",
    "\n",
    "<img src=\"./images/ml-eng.png\">\n",
    "\n",
    "### Deep Learning\n",
    "\n",
    "Fast forward to today and what we’re seeing is a large interest in something called Deep Learning which is a subset of Machine Learning. Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost. The most popular kinds of Deep Learning models, as they are using in large scale image recognition tasks, are known as Convolutional Neural Nets, or simply ConvNets. \n",
    "\n",
    "<img src=\"./images/traditional-ml-deep-learning-2.png\">\n",
    "\n",
    "#### Convolutional Neural Network\n",
    "\n",
    "A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics.\n",
    "\n",
    "The architecture of a ConvNet is analogous to that of the connectivity pattern of Neurons in the Human Brain and was inspired by the organization of the Visual Cortex. Individual neurons respond to stimuli only in a restricted region of the visual field known as the Receptive Field. A collection of such fields overlap to cover the entire visual area.\n",
    "\n",
    "<img src=\"./images/Typical_cnn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\n",
    "\n",
    "#### Input\n",
    "\n",
    "In the figure, we have an RGB image which has been separated by its three color planes — Red, Green, and Blue. There are a number of such color spaces in which images exist — Grayscale, RGB, HSV, CMYK, etc.\n",
    "\n",
    "<img src=\"./images/input-img.png\">\n",
    "\n",
    "You can imagine how computationally intensive things would get once the images reach dimensions, say 8K (7680×4320). The role of the ConvNet is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction.\n",
    "\n",
    "#### Convolution\n",
    "\n",
    "Think of convolution as applying a filter to our image. We pass over a mini image, usually called a kernel, and output the resulting, filtered subset of our image.\n",
    "\n",
    "<img src=\"./images/Convolution_schematic.gif\">\n",
    "\n",
    "The objective of the Convolution Operation is to extract the high-level features such as edges, from the input image.\n",
    "\n",
    "<img src=\"./images/convolution-layer.gif\">\n",
    "\n",
    "There are a few parameters that get adjusted here:\n",
    "\n",
    "    * Kernel Size – the size of the filter.\n",
    "    * Kernel Type – the values of the actual filter. Some examples include identity, edge detection, and sharpen.\n",
    "    * Stride – the rate at which the kernel passes over the input image. A stride of 2 moves the kernel in 2-pixel increments.\n",
    "    * Padding – we can add layers of 0s to the outside of the image in order to make sure that the kernel properly passes over the edges of the image.\n",
    "    * Output Layers – how many different kernels are applied to the image.\n",
    "\n",
    "Output of the convolution process is called the “convolved feature” or “feature map.” \n",
    "\n",
    "#### ReLU\n",
    "CNNs often add in a nonlinear function to help approximate such a relationship in the underlying data. ReLU (Rectified Linear Unit) is one such simple function.\n",
    "\n",
    "#### Max Pooling\n",
    "\n",
    "We pass over sections of our image and pool them into the highest value in the section.\n",
    "\n",
    "Similar to Convolution layer, the pooling layer decreases the computational power required to process the data through dimensionality reduction. Furthermore, it is useful for extracting dominant features which are rotational and positional invariant, thus maintaining the process of effectively training of the model.\n",
    "\n",
    "<img src=\"./images/max-pooling.png\">\n",
    "\n",
    "#### Fully Connected Layers\n",
    "After the above preprocessing steps are applied, the resulting image (which may end up looking nothing like the original!) is passed into the traditional neural network architecture.\n",
    "\n",
    "After going through the above process, we have successfully enabled the model to understand the features. Moving on, we are going to flatten the final output and feed it to a regular Neural Network for classification purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "A replacement for NumPy to use the power of GPUs. \n",
    "\n",
    "Lets construct a randomly initialized matrix. Run the snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.8809e-02, 5.7240e-01, 9.6262e-05],\n",
      "        [7.8903e-01, 7.3890e-01, 8.3572e-01],\n",
      "        [1.6577e-01, 8.9676e-01, 4.5417e-01],\n",
      "        [4.0741e-01, 6.9280e-01, 7.5464e-01],\n",
      "        [6.6123e-01, 6.3295e-01, 3.9002e-01]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch uses an imperative / eager paradigm. That is, each line of code required to build a graph defines a component of that graph. We can independently perform computations on these components itself, even before your graph is built completely. This is called “define-by-run” methodology.\n",
    "\n",
    "<img src=\"./images/pytorch-variable.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors\n",
    "\n",
    "Tensors are nothing but multidimensional arrays. Tensors in PyTorch are similar to numpy’s ndarrays. PyTorch requires the data set to be transformed into a tensor so it can be consumed in the training and testing of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# define a tensor\n",
    "a = torch.FloatTensor([2])\n",
    "b = torch.FloatTensor([3])\n",
    "\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograd module\n",
    "\n",
    "PyTorch uses a technique called automatic differentiation. That is, we have a recorder that records what operations we have performed, and then it replays it backward to compute our gradients. This technique is especially powerful when building neural networks.\n",
    "\n",
    "```\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(train_x)\n",
    "y = Variable(train_y, requires_grad=False) \n",
    "```\n",
    "\n",
    "train_x and train_y are training data and respective labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optim module\n",
    "\n",
    "`torch.optim` is a module that implements various optimization algorithms used for building neural networks.\n",
    "\n",
    "```\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn module\n",
    "\n",
    "PyTorch autograd makes it easy to define computational graphs and take gradients, but raw autograd can be a bit too low-level for defining complex neural networks. This is where the nn module comes into play.\n",
    "\n",
    "```\n",
    "import torch\n",
    "\n",
    "# define model\n",
    "model = torch.nn.Sequential(\n",
    "                 torch.nn.Linear(input_num_units, hidden_num_units),\n",
    "                 torch.nn.ReLU(),\n",
    "                 torch.nn.Linear(hidden_num_units, output_num_units),\n",
    "        )\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "```\n",
    "\n",
    "Now that you know the basic components of PyTorch, you can easily build your own neural network from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters (Constants)\n",
    "\n",
    "The batch size is a number of samples processed before the model is updated.\n",
    "\n",
    "The number of epochs is the number of complete passes through the training dataset.\n",
    "\n",
    "The learning rate or step size in machine learning is a hyperparameter which determines to what extent newly acquired information overrides old information. At the global minima we can be confident that the learning algorithm has achieved a high level of accuracy, and is sufficient for making predictions on test or other unseen data.\n",
    "\n",
    "<img src=\"./images/global-minima.png\">\n",
    "\n",
    "We must specify the batch size, number of epochs and learning rate for any learning algorithm.\n",
    "\n",
    "```\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 0.003\n",
    "```\n",
    "\n",
    "Assuming there is a nice music track that comes with with lyrics and made of six (6) verses that you want to learn. After playing the full music track (`Epoch`) and going through each of the 6 verses (`Iterations`) for the first time, there is no guarrantee you will be able to sing this song on your own without refering to the lyrics or replaying the song. Thus, you may need to replay the song for a sufficient number of times(`Multiple Epochs`) until perfection or confident enough to sing on your own or even recite any verse from any parts of the song (`High learning acuracy`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "PyTorch ships with the torchvision package, which makes it easy to download and use datasets for CNNs.\n",
    "\n",
    "```\n",
    "data = torchvision.datasets.ImageFolder(root=DATA_FOLDER_PATH, transform=TRANSFORM_IMG)\n",
    "data_loader = data.DataLoader(data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "```\n",
    "\n",
    "The transform parameter `TRANSFORM_IMG` can be used to preprocess the images.\n",
    "\n",
    "```\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "                        transforms.Grayscale(num_output_channels=1),\n",
    "                        transforms.ToTensor()\n",
    "                ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing a Neural Net\n",
    "\n",
    "We’ll be making use of four major functions in our CNN class:\n",
    "\n",
    "    * torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding) – applies convolution\n",
    "    * torch.nn.relu(x) – applies ReLU\n",
    "    * torch.nn.MaxPool2d(kernel_size, stride, padding) – applies max pooling\n",
    "    * torch.nn.Linear(in_features, out_features) – fully connected layer (multiply inputs by learned weights)\n",
    "    \n",
    "We will create a CNN class with one class method: forward. The forward() method computes a forward pass of the CNN, which includes the preprocessing steps we outlined above.\n",
    "\n",
    "```\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, \n",
    "                                            #     padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 2) # fully connected layer, output 2 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output, x                    # return x for visualization\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The Neural Net can then be initialized in a single line as.\n",
    "\n",
    "```\n",
    "    model = CNN()\n",
    "```\n",
    "\n",
    "\n",
    "Further the optim model and loss function are defined as below.\n",
    "\n",
    "```\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "```\n",
    "\n",
    "\n",
    "We used the `torch.nn.CrossEntropyLoss()` function. Cross Entropy Loss, also referred to as Log Loss, outputs a probability value between 0 and 1 that increases as the probability of the predicted label diverges from the actual label.\n",
    "\n",
    "\n",
    "Also, to check if GPU is available and to initialize PyTorch on the right device, we can use\n",
    "\n",
    "```\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Neural Net\n",
    "\n",
    "Once we’ve defined the class for our CNN, we need to train the net itself. This is where neural network code gets interesting.Our basic flow is a training loop: each time we pass through the loop (called an “epoch”), we compute a forward pass on the network and implement backpropagation to adjust the weights. We’ll also record some other measurements like loss and time passed, so that we can analyze them as the net trains itself.\n",
    "\n",
    "Finally, we’ll define a function to train our CNN using a simple for loop. During each epoch of training, we pass data to the model in batches whose size we define when we call the training loop. Data is feature-engineered using the SimpleCNN class we’ve defined, and then basic metrics are printed after a few passes. During each loop, we also calculate the loss on our validation set.\n",
    "\n",
    "```\n",
    "    for epoch in range(EPOCHS):\n",
    "        for step, (x, y) in enumerate(train_data_loader):\n",
    "        \n",
    "            b_x = Variable(x.float())   # batch x (image)\n",
    "            b_y = Variable(y)   # batch y (target)\n",
    "    \n",
    "            output = model(b_x)[0]\n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Current Epoch: ', epoch)\n",
    "        print('Current Loss:', loss.data)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracy\n",
    "\n",
    "At the end of every training epoch we test the current accuracy of the model.\n",
    "\n",
    "```\n",
    "        for step, (tx, ty) in enumerate(test_data_loader):\n",
    "\n",
    "            test_x = Variable(tx)\n",
    "            test_y = Variable(ty)\n",
    "            \n",
    "            test_output, last_layer = model(test_x)\n",
    "            \n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / float(test_y.size(0))\n",
    "            \n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data, '| test accuracy: %.2f' % accuracy)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load Model\n",
    "\n",
    "```\n",
    "# Save and load the entire model.\n",
    "torch.save(model, 'model.ckpt')\n",
    "model = torch.load('model.ckpt')\n",
    "\n",
    "# Save and load only the model parameters (recommended).\n",
    "torch.save(model.state_dict(), 'params.ckpt')\n",
    "model.load_state_dict(torch.load('params.ckpt'))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
