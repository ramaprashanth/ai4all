{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition for Human-Robot Interaction using NAO\n",
    "\n",
    "Artificial Intelligence and Human-Robot interaction have been a topic of both science fiction and academic speculation even before any robots existed. These robots can play an extremely vital role to make those who may otherwise need to live in assisted care facilities more independent, to help workers perform their jobs, or simply to make life more convenient. The challenges these fields focus to build an intuitive and easy communication with the robot through speech, gestures and facial expressions. The use of hand gestures provides a better solution than conventional human-machine interfaces. Furthermore, translations of hand gestures can help in accomplishing the ease and naturalness desired for Human-Robot Interaction.This has motivated a very active research concerned with computer vision-based analysis and interpretation of hand gestures.\n",
    "\n",
    "In this project, we aim to implement the hand gesture recognition for robots with modeling, training, classifying and recognizing gestures based on computer vision algorithms and machine learning techniques. We seek to highlight research enabling robots to effectively interact with people autonomously while modeling, planning, and reasoning about the environment that the robot operates in and the tasks that it must perform. AI-HRI deals with the challenge of interacting with humans in environments that are relatively unstructured or which are structured around people rather than machines, as well as the possibility that the robot may need to interact naturally with people rather than through teach pendants, programming, or similar interfaces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/gesture-nao.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design\n",
    "\n",
    "Our goal in this project to implement a system that should be integrated into NAO to recognize hand gestures. We use the image input stream from the stereo camera of the NAO to recognize the gesture and then transalted to robotic actions which should translate the human hand gesture to a robotic hand gesture by imitating hand gestures of the user.\n",
    "\n",
    "In order to recognize gestures, we propose to learn and classify hand gestures by training Convolutional Neural Networks(CNNs) which are a class of deep neural networks, most commonly applied to analyzing visual imagery and can be used to predict the hand gestures in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/nao-design.png\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "NAO - Humanoid Robot\n",
    "\n",
    "    Humanoid Robot from Aldebaran Robotics\n",
    "    25 Degrees of Freedom\n",
    "    Intel Atom @ 1.6 GHz\n",
    "    1GB RAM\n",
    "    32-bit Gentoo Linux\n",
    "    Real-time OS patched\n",
    "    NAOqi SDK in C++, Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/nao-body.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform\n",
    "\n",
    "Python 2.7\n",
    "\n",
    "This project works best on Ubuntu 16.04 LTS(Xenial Xerus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "OpenCV 3.0\n",
    "\n",
    "Numpy\n",
    "\n",
    "PyTorch\n",
    "\n",
    "NAOqi (Python 2.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook Setup\n",
    "\n",
    "Jupyter Notebook can be installed using \n",
    "\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "If you installed jupyter using pip3(Python 3),Jupyter Notebook Python2 Kernal can be installed using\n",
    "\n",
    "```\n",
    "python2 -m pip install ipykernel --user\n",
    "python2 -m install ipykernel --user\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
